# Ican.speak

This project implements a Sign Language to Text Converter using Deep Learning techniques. The system recognizes hand gestures from images and converts them into corresponding text representations of American Sign Language (ASL) alphabets.

A Convolutional Neural Network (CNN) is used to classify hand gesture images into predefined sign language classes. The model is trained on an image-based dataset and can be extended for real-time gesture recognition using a webcam.
